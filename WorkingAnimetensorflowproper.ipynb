{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "WorkingAnimetensorflowproper",
      "provenance": [],
      "collapsed_sections": [
        "aBYb7NLMXgjI",
        "s0RzFIXLYQyV"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtolps/TensorflowCats2DogsUGATIT/blob/master/WorkingAnimetensorflowproper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70vtsoUS6uOx"
      },
      "source": [
        "# UGATIT Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mjEeKZznQ24"
      },
      "source": [
        "### Install stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp00Z9ChSHk6"
      },
      "source": [
        "Uninstall new tensor flow and install old one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka3ptNwyFYIF"
      },
      "source": [
        "!pip uninstall -y tensorflow\r\n",
        "!pip install opencv-python matplotlib numpy Pillow Flask imutils tensorflow-gpu==1.14.0 awscli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzsOCTPl_S9q"
      },
      "source": [
        "from platform import python_version\r\n",
        "\r\n",
        "print(python_version())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-BiNZPds_hh"
      },
      "source": [
        "!pip install git+https://github.com/onnx/tensorflow-onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP67mRDjnQ24"
      },
      "source": [
        "!git clone https://github.com/rtolps/TensorflowCats2DogsUGATIT\n",
        "%cd TensorflowCats2DogsUGATIT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBYb7NLMXgjI"
      },
      "source": [
        "#(Optional) install Bazel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMDy6vVbGeE9"
      },
      "source": [
        "BAZEL_VERSION = '0.20.0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZGUNkM0Ge8I"
      },
      "source": [
        "!wget https://github.com/bazelbuild/bazel/releases/download/{BAZEL_VERSION}/bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsALaqOhGi_F"
      },
      "source": [
        "!chmod +x bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Vx_j01GyZb"
      },
      "source": [
        "!./bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb7147tGG6FD"
      },
      "source": [
        "!bazel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0RzFIXLYQyV"
      },
      "source": [
        "# Import Other Stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoVDtyB4EHva"
      },
      "source": [
        "Import Summary tool\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIypNE2v_rqE"
      },
      "source": [
        "import tensorflow.tools.graph_transforms as graph_transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfeumM3EFls"
      },
      "source": [
        "Import graph freezer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jskBX6usEDFG"
      },
      "source": [
        "from tensorflow.python.tools import freeze_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyhJ_AqPuaGt"
      },
      "source": [
        "Mount google drive (if you want to put in pretrained model) and unzip checkpoint folder make sure containing file within checkpoint folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNFUujptx_-"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaTwk78buYSM"
      },
      "source": [
        "!unzip checkpoint.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Baukq28HNX"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4tZ96A8IMY"
      },
      "source": [
        "!python main.py --dataset cat2dog --phase train --light True --iteration 50 --epoch 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyi62BmT8LOa"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1KNKOBv8MAX"
      },
      "source": [
        "!python main.py --dataset cat2dog --phase test --light True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_sQbKL7f4I"
      },
      "source": [
        "Convert Graph using code from the Github page of anime tensorflow in closed issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZy7AwyuYG0n"
      },
      "source": [
        "# **Export** (I fixed all of the errors with the script, it outputs frozen graph!!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN0meVKIiIhU"
      },
      "source": [
        "!mkdir graphyfreezy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym7olU6QgDqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532008d7-c8a2-44da-db87-8cc91296815e"
      },
      "source": [
        "!python freezeGraph.py --checkpoint_dir checkpoint/UGATIT_light_cat2dog_lsgan_4resblock_6dis_1_1_10_10_1000_sn_smoothing --output output"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "meta_graph is  ['UGATIT_light.model-24000.meta']\n",
            "WARNING:tensorflow:From freezeGraph.py:19: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-12-24 08:01:19.010776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-24 08:01:19.039014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.039642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-24 08:01:19.039936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-24 08:01:19.041793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-24 08:01:19.043193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-24 08:01:19.043587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-24 08:01:19.052677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-24 08:01:19.053999: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-24 08:01:19.065017: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-24 08:01:19.065136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.065744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.066399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-12-24 08:01:19.066756: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-12-24 08:01:19.160971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.161731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c02d80 executing computations on platform CUDA. Devices:\n",
            "2020-12-24 08:01:19.161776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2020-12-24 08:01:19.163586: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-12-24 08:01:19.163783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c01dc0 executing computations on platform Host. Devices:\n",
            "2020-12-24 08:01:19.163822: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-12-24 08:01:19.164026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.164739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-24 08:01:19.164842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-24 08:01:19.164887: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-24 08:01:19.164916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-24 08:01:19.164937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-24 08:01:19.164957: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-24 08:01:19.164980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-24 08:01:19.165003: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-24 08:01:19.165088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.165676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.166226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-12-24 08:01:19.166297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-24 08:01:19.167638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-24 08:01:19.167667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2020-12-24 08:01:19.167678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2020-12-24 08:01:19.167800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.168478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.169132: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-12-24 08:01:19.169176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15024 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "WARNING:tensorflow:From freezeGraph.py:20: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "WARNING:tensorflow:From freezeGraph.py:22: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From freezeGraph.py:27: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "WARNING:tensorflow:From freezeGraph.py:29: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmQ9YjnQKiYu"
      },
      "source": [
        "# Clean up frozen graph per [snapchat's requirements](https://lensstudio.snapchat.com/guides/machine-learning/ml-frameworks/export-from-tensorflow/) (this doesn't seem to work)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u73DUzXtKvEh"
      },
      "source": [
        "!python cleanup.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crbeczJcabIq"
      },
      "source": [
        "# This code seems to work better, at least it outputs a file. File is really big (40MB) and doesn't look that much different from unoptomized file and needs to go on a little diet to make it less than 10MB if that is possible using [this method](https://stackoverflow.com/questions/51957336/how-to-properly-reduce-the-size-of-a-tensorflow-savedmodel) or one of [these methods](https://www.programcreek.com/python/example/114582/tensorflow.tools.graph_transforms.TransformGraph). Also it can't have \"minimum\" nodes, they're not compatible with snapchat but when I used the pretrained model there are no minimum nodes in the graph so solution found? However I get an error saying transpose layer not supported. I don't know if that's even possible but I will try my best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiEncRi2afZn"
      },
      "source": [
        "# export optimized graph\r\n",
        "from tensorflow.tools.graph_transforms import TransformGraph\r\n",
        " \r\n",
        "frozen_graph_filename = 'output.pb'\r\n",
        "input_node_names = ['OneShotIterator']\r\n",
        "output_node_names = ['generator_B/Tanh']\r\n",
        "optimized_graph_def_from_pb  = export_from_frozen_graph(frozen_graph_filename, input_node_names, output_node_names, output_filename='output_optimized.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpLxyIien9f"
      },
      "source": [
        "#Attempted code from stack overflow (this is very broken)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr_EV7wMeq39"
      },
      "source": [
        "from tensorflow.python.tools import freeze_graph\r\n",
        "from tensorflow.tools.graph_transforms import TransformGraph\r\n",
        "\r\n",
        "def get_graph_def_from_file(graph_filepath):\r\n",
        "  with ops.Graph().as_default():\r\n",
        "    with tf.gfile.GFile(graph_filepath, 'rb') as f:\r\n",
        "      graph_def = tf.GraphDef()\r\n",
        "      graph_def.ParseFromString(f.read())\r\n",
        "      return graph_def\r\n",
        "\r\n",
        "def optimize_graph(model_dir, graph_filename, transforms, output_node):\r\n",
        "  input_names = []\r\n",
        "  output_names = [output_node]\r\n",
        "  if graph_filename is None:\r\n",
        "    graph_def = get_graph_def_from_saved_model(model_dir)\r\n",
        "  else:\r\n",
        "    graph_def = get_graph_def_from_file(os.path.join(model_dir, \r\n",
        "         graph_filename))\r\n",
        "  optimized_graph_def = TransformGraph(graph_def, input_names,      \r\n",
        "      output_names, transforms)\r\n",
        "  tf.train.write_graph(optimized_graph_def, logdir=model_dir, as_text=False, \r\n",
        "     name='optimized_model.pb')\r\n",
        "  print('Graph optimized!')\r\n",
        "\r\n",
        "  transforms = ['remove_nodes(op=Identity)', 'merge_duplicate_nodes',\r\n",
        " 'strip_unused_nodes','fold_constants(ignore_errors=true)',\r\n",
        " 'fold_batch_norms']\r\n",
        "\r\n",
        "optimize_graph(saved_model_dir, \"output.pb\" , transforms, 'head/predictions/class_ids')\r\n",
        "\r\n",
        "def convert_graph_def_to_saved_model(export_dir, graph_filepath):\r\n",
        "  if tf.gfile.Exists(export_dir):\r\n",
        "    tf.gfile.DeleteRecursively(export_dir)\r\n",
        "  graph_def = get_graph_def_from_file(graph_filepath)\r\n",
        "  with tf.Session(graph=tf.Graph()) as session:\r\n",
        "    tf.import_graph_def(graph_def, name='')\r\n",
        "    tf.saved_model.simple_save(\r\n",
        "        session,\r\n",
        "        export_dir,\r\n",
        "        inputs={\r\n",
        "            node.name: session.graph.get_tensor_by_name(\r\n",
        "                '{}:0'.format(node.name))\r\n",
        "            for node in graph_def.node if node.op=='Placeholder'},\r\n",
        "        outputs={'class_ids': session.graph.get_tensor_by_name(\r\n",
        "            'head/predictions/class_ids:0')}\r\n",
        "    )\r\n",
        "    print('Optimized graph converted to SavedModel!')\r\n",
        "\r\n",
        "optimized_export_dir = os.path.join(export_dir, 'optimized')\r\n",
        "optimized_filepath = os.path.join(saved_model_dir, 'optimized_model.pb')\r\n",
        "convert_graph_def_to_saved_model(optimized_export_dir, optimized_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}