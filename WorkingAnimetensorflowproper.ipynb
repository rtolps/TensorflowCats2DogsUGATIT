{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "WorkingAnimetensorflowproper",
      "provenance": [],
      "collapsed_sections": [
        "aBYb7NLMXgjI",
        "s0RzFIXLYQyV"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtolps/TensorflowCats2DogsUGATIT/blob/master/WorkingAnimetensorflowproper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70vtsoUS6uOx"
      },
      "source": [
        "# UGATIT Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mjEeKZznQ24"
      },
      "source": [
        "### Install stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp00Z9ChSHk6"
      },
      "source": [
        "Uninstall new tensor flow and install old one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka3ptNwyFYIF"
      },
      "source": [
        "!pip uninstall -y tensorflow\r\n",
        "!pip install opencv-python matplotlib numpy Pillow Flask imutils tensorflow-gpu==1.14.0 awscli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzsOCTPl_S9q"
      },
      "source": [
        "from platform import python_version\r\n",
        "\r\n",
        "print(python_version())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-BiNZPds_hh"
      },
      "source": [
        "!pip install git+https://github.com/onnx/tensorflow-onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP67mRDjnQ24"
      },
      "source": [
        "!git clone https://github.com/rtolps/TensorflowCats2DogsUGATIT\n",
        "%cd TensorflowCats2DogsUGATIT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBYb7NLMXgjI"
      },
      "source": [
        "#Install Bazel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMDy6vVbGeE9"
      },
      "source": [
        "BAZEL_VERSION = '0.20.0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZGUNkM0Ge8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a45202e-fba9-496d-fc6b-2db057d72241"
      },
      "source": [
        "!wget https://github.com/bazelbuild/bazel/releases/download/{BAZEL_VERSION}/bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-24 08:45:16--  https://github.com/bazelbuild/bazel/releases/download/0.20.0/bazel-0.20.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/16e3fc80-f4b8-11e8-9fbb-d3e0922a0573?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201224%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201224T084516Z&X-Amz-Expires=300&X-Amz-Signature=acba0930e867704cbdefa2ccc86884defa827f2d0fb55326204e2ffec7eb4471&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-0.20.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-12-24 08:45:16--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/16e3fc80-f4b8-11e8-9fbb-d3e0922a0573?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201224%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201224T084516Z&X-Amz-Expires=300&X-Amz-Signature=acba0930e867704cbdefa2ccc86884defa827f2d0fb55326204e2ffec7eb4471&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-0.20.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.128.3\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.128.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170853024 (163M) [application/octet-stream]\n",
            "Saving to: ‘bazel-0.20.0-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-0.20.0-instal 100%[===================>] 162.94M  17.0MB/s    in 11s     \n",
            "\n",
            "2020-12-24 08:45:28 (14.6 MB/s) - ‘bazel-0.20.0-installer-linux-x86_64.sh’ saved [170853024/170853024]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsALaqOhGi_F"
      },
      "source": [
        "!chmod +x bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Vx_j01GyZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbfa6be5-c934-4df0-c680-7b139995d8c4"
      },
      "source": [
        "!./bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.20.0 (2018-11-30)\n",
            "\n",
            "Baseline: 7bf7f031c332dc483257248d1c1f98ad75bbc83b\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + fd52341505e725487c6bc6dfbe6b5e081aa037da:\n",
            "     update bazel-toolchains pin to latest release Part of changes to\n",
            "     allow bazelci to use 0.19.0 configs. RBE toolchain configs at or\n",
            "     before 0.17.0 are not compatible with bazel 0.19.0 or above.\n",
            "   + 241f28d05424db2d11ee245dc856b992258505e3:\n",
            "     Revert \"Toggle --incompatible_disable_late_bound_option_defaults\n",
            "     flag.\"\n",
            "   + f7e5aef145c33968f658eb2260e25630dc41cc67:\n",
            "     Add cc_toolchain targets for the new entries in the default\n",
            "     cc_toolchain_suite.\n",
            "   + d2920e32ec7f3f8551a693d33c17b19f1b802145:\n",
            "     Revert \"WindowsFileSystem: open files with delete-sharing\"\n",
            "\n",
            "[Breaking changes in 0.20](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Abreaking-change-0.20)\n",
            "\n",
            "  - [--incompatible_remove_native_http_archive](https://github.com/bazelbuild/bazel/issues/6570).\n",
            "  - [--incompatible_remove_native_git_repository](https://github.com/bazelbuild/bazel/issues/6569).\n",
            "  - [--incompatible_disable_cc_toolchain_label_from_crosstool_proto](https://github.com/bazelbuild/bazel/issues/6434).\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6384).\n",
            "  - [--incompatible_disable_cc_configuration_make_variables](https://github.com/bazelbuild/bazel/issues/6381).\n",
            "  - [--incompatible_disallow_conflicting_providers](https://github.com/bazelbuild/bazel/issues/5902).\n",
            "  - [--incompatible_range_type](https://github.com/bazelbuild/bazel/issues/5264).\n",
            "\n",
            "[0.20 is a migration window for the following changes](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Amigration-0.20)\n",
            "\n",
            "  - [--incompatible_use_jdk10_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6661)\n",
            "  - [--incompatible_use_remotejdk_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6656)\n",
            "  - [--incompatible_disable_sysroot_from_configuration](https://github.com/bazelbuild/bazel/issues/6565)\n",
            "  - [--incompatible_provide_cc_toolchain_info_from_cc_toolchain_suite](https://github.com/bazelbuild/bazel/issues/6537)\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6383)\n",
            "  - [--incompatible_package_name_is_a_function](https://github.com/bazelbuild/bazel/issues/5827)\n",
            "\n",
            "[Breaking changes in the next release (0.21)](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Abreaking-change-0.21)\n",
            "\n",
            "  - [--incompatible_use_jdk10_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6661)\n",
            "  - [--incompatible_use_remotejdk_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6656)\n",
            "  - [--incompatible_disable_sysroot_from_configuration](https://github.com/bazelbuild/bazel/issues/6565)\n",
            "  - [--incompatible_provide_cc_toolchain_info_from_cc_toolchain_suite](https://github.com/bazelbuild/bazel/issues/6537)\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6383)\n",
            "  - [--incompatible_disallow_data_transition](https://github.com/bazelbuild/bazel/issues/6153)\n",
            "  - [--incompatible_package_name_is_a_function](https://github.com/bazelbuild/bazel/issues/5827)\n",
            "  - [--incompatible_disallow_slash_operator](https://github.com/bazelbuild/bazel/issues/5823)\n",
            "  - [--incompatible_static_name_resolution](https://github.com/bazelbuild/bazel/issues/5637)\n",
            "\n",
            "Incompatible changes:\n",
            "\n",
            "  - the --experimental_no_dotd_scanning_with_modules command line\n",
            "    argument is not supported anymore.\n",
            "  - The --prune_cpp_modules command line option is not supported\n",
            "    anymore.\n",
            "  - the --experimental_prune_cpp_input_discovery command line option\n",
            "    is not supported anymore.\n",
            "\n",
            "New features:\n",
            "\n",
            "  - Added support for Android NDK r18.\n",
            "\n",
            "Important changes:\n",
            "\n",
            "  - The 'default' parameter of attr.output and attr.output_list is\n",
            "    removed. This is controlled by\n",
            "    --incompatible_no_output_attr_default\n",
            "  - A number of platform-related Starlark APIs which were previously\n",
            "    marked \"experimental\" are now disabled by default, and may be\n",
            "    enabled via --experimental_platforms_api\n",
            "  - Make legacy-test-support (\"legacy_test-<api-level>\") from\n",
            "    android_sdk_repository neverlink. The legacy test support\n",
            "    libraries shouldn't be built into test binaries. To make them\n",
            "    available at runtime, developers should declare them via\n",
            "    uses-library:\n",
            "    https://developer.android.com/training/testing/set-up-project#andr\n",
            "    oid-test-base\n",
            "  - query remote server Capabilities (per REAPI v2)\n",
            "  - CppRules: All cc_toolchains depended on from\n",
            "    cc_toolchain_suite.toolchains are now analyzed when not using\n",
            "    platforms in order to select the right cc_toolchain.\n",
            "  - removed obsolete --explicit_jre_deps flag.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - Improve error messaging when unsupport proguard options are\n",
            "    specified at the library level.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - The --incompatible_disable_late_bound_option_defaults flag has\n",
            "    been flipped (#6384)\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_flags_cc_toolchain_api was flipped\n",
            "    (#6434)\n",
            "  - Fixed issue where ctx.resolve_command created conflicting\n",
            "    intermediate files when resolve_command was called multiple times\n",
            "    within the same rule invocation with a long command attribute.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_cc_configuration_make_variables was\n",
            "    flipped (#6381)\n",
            "  - If the --javabase flag is unset, it Bazel locates a JDK using\n",
            "    the JAVA_HOME environment variable and searching the PATH. If no\n",
            "    JDK is found --javabase will be empty, and builds targeting Java\n",
            "    will not\n",
            "    be supported. Previously Bazel would fall back to using the\n",
            "    embedded\n",
            "    JDK as a --javabase, but this is no longer default behaviour. A\n",
            "    JDK should\n",
            "    be explicitly installed instead to enable Java development\n",
            "  - Bazel will now shut down when idle for 5 minutes and the system\n",
            "    is low on RAM (linux only).\n",
            "  - CROSSTOOL file is now read from the package of cc_toolchain, not\n",
            "    from\n",
            "    the package of cc_toolchain_suite. This is not expected to break\n",
            "    anybody since\n",
            "    cc_toolchain_suite and cc_toolchain are commonly in the same\n",
            "    package.\n",
            "  - All overrides of Starlark's ctx.new_file function are now\n",
            "    deprecated.\n",
            "      Try the `--incompatible_new_actions_api` flag to ensure your\n",
            "    code is forward-compatible.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - Introduce --(no)shutdown_on_low_sys_mem startup flag to toggle\n",
            "    idle low-memory shutdown, disabled by default.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - CppRules: All cc_toolchains depended on from\n",
            "    cc_toolchain_suite.toolchains are now analyzed when not using\n",
            "    platforms in order to select the right cc_toolchain.\n",
            "  - The function `attr.license` is deprecated and will be removed.\n",
            "      It can be disabled now with `--incompatible_no_attr_license`.\n",
            "  - `range()` function now returns a lazy value\n",
            "    (`--incompatible_range_type` is now set by default).\n",
            "  - The code coverage report now includes the actual paths to header\n",
            "    files instead of the ugly,\n",
            "    Bazel generated, virtual includes path.\n",
            "  - `--incompatible_disallow_conflicting_providers` has been switched\n",
            "    to true\n",
            "  - Add new flag `--incompatible_disable_systool_from_configration` to\n",
            "    disable loading the systool from CppConfiguration.\n",
            "  - Add new flag `--incompatible_disable_sysroot_from_configuration`\n",
            "    to\n",
            "    disable loading the systool from CppConfiguration.\n",
            "  - Sorting remote Platform properties for remote execution. May\n",
            "    affect cache keys!\n",
            "  - Use different server log files per Bazel server process; java.log\n",
            "    is\n",
            "    now a symlink to the latest log.\n",
            "\n",
            "This release contains contributions from many people at Google, as well as a7g4 <a7g4@a7g4.net>, Alan <alan.agius@betssongroup.com>, Asaf Flescher <asafflesch@gmail.com>, Benjamin Peterson <bp@benjamin.pe>, Ed Schouten <ed.schouten@prodrive-technologies.com>, George Gensure <ggensure@uber.com>, George Kalpakas <kalpakas.g@gmail.com>, Greg <gregestren@users.noreply.github.com>, Irina Iancu <iirina@users.noreply.github.com>, Keith Smiley <keithbsmiley@gmail.com>, Loo Rong Jie <loorongjie@gmail.com>, Mark Zeren <mzeren@vmware.com>, Petros Eskinder <petroseskinder@users.noreply.github.com>, rachcatch <rachelcatchpoole@hotmail.com>, Robert Brown <robert.brown@gmail.com>, Robert Gay <robert.gay@redfin.com>, Salty Egg <2281521+zhouhao@users.noreply.github.com>.\n",
            "\n",
            "## Build informations\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/2987897)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/usr/local/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /usr/local/lib/bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb7147tGG6FD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ad7e71-5dcb-4368-ad08-bbf45d035d4e"
      },
      "source": [
        "!bazel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting Bazel installation...\n",
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n",
            "INFO: Invocation ID: 0e4d515d-8eab-42ab-ab21-12b9e635021d\n",
            "                                                          [bazel release 0.20.0]\n",
            "Usage: bazel <command> <options> ...\n",
            "\n",
            "Available commands:\n",
            "  analyze-profile     Analyzes build profile data.\n",
            "  aquery              Analyzes the given targets and queries the action graph.\n",
            "  build               Builds the specified targets.\n",
            "  canonicalize-flags  Canonicalizes a list of bazel options.\n",
            "  clean               Removes output files and optionally stops the server.\n",
            "  coverage            Generates code coverage report for specified test targets.\n",
            "  cquery              Loads, analyzes, and queries the specified targets w/ configurations.\n",
            "  dump                Dumps the internal state of the bazel server process.\n",
            "  fetch               Fetches external repositories that are prerequisites to the targets.\n",
            "  help                Prints help for commands, or the index.\n",
            "  info                Displays runtime info about the bazel server.\n",
            "  license             Prints the license of this software.\n",
            "  mobile-install      Installs targets to mobile devices.\n",
            "  print_action        Prints the command line args for compiling a file.\n",
            "  query               Executes a dependency graph query.\n",
            "  run                 Runs the specified target.\n",
            "  shutdown            Stops the bazel server.\n",
            "  sync                Syncs all repositories specifed in the workspace file\n",
            "  test                Builds and runs the specified test targets.\n",
            "  version             Prints version information for bazel.\n",
            "\n",
            "Getting more help:\n",
            "  bazel help <command>\n",
            "                   Prints help and options for <command>.\n",
            "  bazel help startup_options\n",
            "                   Options for the JVM hosting bazel.\n",
            "  bazel help target-syntax\n",
            "                   Explains the syntax for specifying targets.\n",
            "  bazel help info-keys\n",
            "                   Displays a list of keys used by the info command.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0RzFIXLYQyV"
      },
      "source": [
        "# Import Other Stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoVDtyB4EHva"
      },
      "source": [
        "Import Summary tool\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIypNE2v_rqE"
      },
      "source": [
        "import tensorflow.tools.graph_transforms as graph_transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfeumM3EFls"
      },
      "source": [
        "Import graph freezer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jskBX6usEDFG"
      },
      "source": [
        "from tensorflow.python.tools import freeze_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyhJ_AqPuaGt"
      },
      "source": [
        "#Mount google drive (if you want to put in pretrained model) and unzip checkpoint folder make sure containing file within checkpoint folder. Make sure file name has smoothing at the end. Train the model a little for an example of what the file name is and  then replace data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNFUujptx_-"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaTwk78buYSM"
      },
      "source": [
        "!unzip checkpoint.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Baukq28HNX"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4tZ96A8IMY"
      },
      "source": [
        "!python main.py --dataset cat2dog --phase train --light True --iteration 50 --epoch 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyi62BmT8LOa"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1KNKOBv8MAX"
      },
      "source": [
        "!python main.py --dataset cat2dog --phase test --light True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_sQbKL7f4I"
      },
      "source": [
        "Convert Graph using code from the Github page of anime tensorflow in closed issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZy7AwyuYG0n"
      },
      "source": [
        "# **Export** (I fixed all of the errors with the script, it outputs frozen graph!!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN0meVKIiIhU"
      },
      "source": [
        "!mkdir graphyfreezy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym7olU6QgDqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532008d7-c8a2-44da-db87-8cc91296815e"
      },
      "source": [
        "!python freezeGraph.py --checkpoint_dir checkpoint/UGATIT_light_cat2dog_lsgan_4resblock_6dis_1_1_10_10_1000_sn_smoothing --output output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "meta_graph is  ['UGATIT_light.model-24000.meta']\n",
            "WARNING:tensorflow:From freezeGraph.py:19: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-12-24 08:01:19.010776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-24 08:01:19.039014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.039642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-24 08:01:19.039936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-24 08:01:19.041793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-24 08:01:19.043193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-24 08:01:19.043587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-24 08:01:19.052677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-24 08:01:19.053999: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-24 08:01:19.065017: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-24 08:01:19.065136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.065744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.066399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-12-24 08:01:19.066756: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-12-24 08:01:19.160971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.161731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c02d80 executing computations on platform CUDA. Devices:\n",
            "2020-12-24 08:01:19.161776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2020-12-24 08:01:19.163586: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-12-24 08:01:19.163783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c01dc0 executing computations on platform Host. Devices:\n",
            "2020-12-24 08:01:19.163822: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-12-24 08:01:19.164026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.164739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-24 08:01:19.164842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-24 08:01:19.164887: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-24 08:01:19.164916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-24 08:01:19.164937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-24 08:01:19.164957: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-24 08:01:19.164980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-24 08:01:19.165003: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-24 08:01:19.165088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.165676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.166226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-12-24 08:01:19.166297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-24 08:01:19.167638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-24 08:01:19.167667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2020-12-24 08:01:19.167678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2020-12-24 08:01:19.167800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.168478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-24 08:01:19.169132: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-12-24 08:01:19.169176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15024 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "WARNING:tensorflow:From freezeGraph.py:20: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "WARNING:tensorflow:From freezeGraph.py:22: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From freezeGraph.py:27: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "WARNING:tensorflow:From freezeGraph.py:29: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmQ9YjnQKiYu"
      },
      "source": [
        "# Clean up frozen graph per [snapchat's requirements](https://lensstudio.snapchat.com/guides/machine-learning/ml-frameworks/export-from-tensorflow/) (this doesn't seem to work)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u73DUzXtKvEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400f802f-0996-4355-bc5e-14381d10866d"
      },
      "source": [
        "!python cleanup.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crbeczJcabIq"
      },
      "source": [
        "# This code seems to work better, at least it outputs a file. (update, something broke this) File is really big (40MB) and doesn't look that much different from unoptomized file and needs to go on a little diet to make it less than 10MB if that is possible using [this method](https://stackoverflow.com/questions/51957336/how-to-properly-reduce-the-size-of-a-tensorflow-savedmodel) or one of [these methods](https://www.programcreek.com/python/example/114582/tensorflow.tools.graph_transforms.TransformGraph). Graph is probably 32 bit. Squishing it down to 8 bit would make it one quarter the size plus a little pruning it could be possible. Also it can't have \"minimum\" nodes, they're not compatible with snapchat but when I used the pretrained model there are no minimum nodes in the graph so solution found? However I get an error saying transpose layer not supported. I don't know if that's even possible but I will try my best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B21VJYZF5Crg",
        "outputId": "4a848493-9f8a-4de9-a19b-8eefe8f0ed4a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `tflite_convert --graph_def_file=<your_frozen_graph> --output_file=<your_chosen_output_location> --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --inference_type=QUANTIZED_UINT8 --output_arrays=<your_output_arrays> --input_arrays=<your_input_arrays> --mean_values=<mean of input training data> --std_dev_values=<standard deviation of input training data>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiEncRi2afZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "3bd61883-3655-4760-c305-8132d4e1a175"
      },
      "source": [
        "# export optimized graph\r\n",
        "\r\n",
        "from tensorflow.tools.graph_transforms import TransformGraph\r\n",
        " \r\n",
        "frozen_graph_filename = 'output.pb'\r\n",
        "input_node_names = ['OneShotIterator']\r\n",
        "output_node_names = ['generator_B/Tanh']\r\n",
        "optimized_graph_def_from_pb  = export_from_frozen_graph(frozen_graph_filename, input_node_names, output_node_names, output_filename='output_optimized.pb')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a4fbaccca788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_node_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'OneShotIterator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput_node_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'generator_B/Tanh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moptimized_graph_def_from_pb\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mexport_from_frozen_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozen_graph_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_node_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_optimized.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'export_from_frozen_graph' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0ykG9sX6q4Y",
        "outputId": "9c9bc74c-65b8-48ea-fb8f-4db8e4e30317"
      },
      "source": [
        "!touch WORKSPACE\r\n",
        "!bazel build tensorflow/python/tools:optimize_for_inference && \\\r\n",
        "!bazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n",
        "--input_graph=some_graph_def.pb \\\r\n",
        "--output_graph=/tmp/optimized_graph.pb \\\r\n",
        "--input_names=Mul \\\r\n",
        "--output_names=softmax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "Starting local Bazel server and connecting to it...\n",
            "\u001b[32mINFO: \u001b[0mInvocation ID: 3bf662ff-f000-4c14-bbb8-eaed5ea0b62f\n",
            "\u001b[31m\u001b[1mERROR: \u001b[0mSkipping 'tensorflow/python/tools:optimize_for_inference': no such package 'tensorflow/python/tools': BUILD file not found on package path\n",
            "\u001b[35mWARNING: \u001b[0mTarget pattern parsing failed.\n",
            "\u001b[31m\u001b[1mERROR: \u001b[0mno such package 'tensorflow/python/tools': BUILD file not found on package path\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 2.606s\n",
            "\u001b[32mINFO: \u001b[0m0 processes.\n",
            "\u001b[31m\u001b[1mFAILED:\u001b[0m Build did NOT complete successfully (0 packages loaded)\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpLxyIien9f"
      },
      "source": [
        "#Attempted code from stack overflow (this is very broken)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr_EV7wMeq39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "09ecfadd-1d70-473a-9cf7-c07ad9b39d18"
      },
      "source": [
        "from tensorflow.python.tools import freeze_graph\r\n",
        "from tensorflow.tools.graph_transforms import TransformGraph\r\n",
        "\r\n",
        "def get_graph_def_from_file(graph_filepath):\r\n",
        "  with ops.Graph().as_default():\r\n",
        "    with tf.gfile.GFile(graph_filepath, 'rb') as f:\r\n",
        "      graph_def = tf.GraphDef()\r\n",
        "      graph_def.ParseFromString(f.read())\r\n",
        "      return graph_def\r\n",
        "\r\n",
        "def optimize_graph(model_dir, graph_filename, transforms, output_node):\r\n",
        "  input_names = []\r\n",
        "  output_names = [output_node]\r\n",
        "  if graph_filename is None:\r\n",
        "    graph_def = get_graph_def_from_saved_model(model_dir)\r\n",
        "  else:\r\n",
        "    graph_def = get_graph_def_from_file(os.path.join(model_dir, \r\n",
        "         graph_filename))\r\n",
        "  optimized_graph_def = TransformGraph(graph_def, input_names,      \r\n",
        "      output_names, transforms)\r\n",
        "  tf.train.write_graph(optimized_graph_def, logdir=model_dir, as_text=False, \r\n",
        "     name='optimized_model.pb')\r\n",
        "  print('Graph optimized!')\r\n",
        "\r\n",
        "  transforms = ['remove_nodes(op=Identity)', 'merge_duplicate_nodes',\r\n",
        " 'strip_unused_nodes','fold_constants(ignore_errors=true)',\r\n",
        " 'fold_batch_norms']\r\n",
        "\r\n",
        "optimize_graph(saved_model_dir, \"output.pb\" , transforms, 'head/predictions/class_ids')\r\n",
        "\r\n",
        "def convert_graph_def_to_saved_model(export_dir, graph_filepath):\r\n",
        "  if tf.gfile.Exists(export_dir):\r\n",
        "    tf.gfile.DeleteRecursively(export_dir)\r\n",
        "  graph_def = get_graph_def_from_file(graph_filepath)\r\n",
        "  with tf.Session(graph=tf.Graph()) as session:\r\n",
        "    tf.import_graph_def(graph_def, name='')\r\n",
        "    tf.saved_model.simple_save(\r\n",
        "        session,\r\n",
        "        export_dir,\r\n",
        "        inputs={\r\n",
        "            node.name: session.graph.get_tensor_by_name(\r\n",
        "                '{}:0'.format(node.name))\r\n",
        "            for node in graph_def.node if node.op=='Placeholder'},\r\n",
        "        outputs={'class_ids': session.graph.get_tensor_by_name(\r\n",
        "            'head/predictions/class_ids:0')}\r\n",
        "    )\r\n",
        "    print('Optimized graph converted to SavedModel!')\r\n",
        "\r\n",
        "optimized_export_dir = os.path.join(export_dir, 'optimized')\r\n",
        "optimized_filepath = os.path.join(saved_model_dir, 'optimized_model.pb')\r\n",
        "convert_graph_def_to_saved_model(optimized_export_dir, optimized_filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9548f39328b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m  'fold_batch_norms']\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0moptimize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output.pb\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'head/predictions/class_ids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_graph_def_to_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'saved_model_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w98D4qjQ_fd-"
      },
      "source": [
        "# Maybe convert to ONNX? (broken)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9P6-p879hNM",
        "outputId": "5fa7875f-7a31-479e-c339-82e9186754ac"
      },
      "source": [
        "!python -m tf2onnx.convert --saved-model /content/TensorflowCats2DogsUGATIT/saved_model tensorflow-model-path /content/TensorflowCats2DogsUGATIT/tensorflow_model_path --output model.onnx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "usage: convert.py [-h] [--input INPUT] [--graphdef GRAPHDEF]\n",
            "                  [--saved-model SAVED_MODEL] [--tag TAG]\n",
            "                  [--signature_def SIGNATURE_DEF]\n",
            "                  [--concrete_function CONCRETE_FUNCTION]\n",
            "                  [--checkpoint CHECKPOINT] [--keras KERAS] [--large_model]\n",
            "                  [--output OUTPUT] [--inputs INPUTS] [--outputs OUTPUTS]\n",
            "                  [--opset OPSET] [--custom-ops CUSTOM_OPS]\n",
            "                  [--extra_opset EXTRA_OPSET] [--target {rs4,rs5,rs6,caffe2}]\n",
            "                  [--continue_on_error] [--verbose] [--debug]\n",
            "                  [--output_frozen_graph OUTPUT_FROZEN_GRAPH] [--fold_const]\n",
            "                  [--inputs-as-nchw INPUTS_AS_NCHW]\n",
            "convert.py: error: unrecognized arguments: tensorflow-model-path /content/TensorflowCats2DogsUGATIT/tensorflow_model_path\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}